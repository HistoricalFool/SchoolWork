%% Homework 3 - ECON 8070 %%
\documentclass[10pt, a4paper]{article}
\usepackage[top=3cm, bottom=4cm, left=3.5cm, right=3.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd, fancyhdr, color, comment, graphicx, environ}
\usepackage{float}
\usepackage{mathrsfs}
\usepackage[math-style=ISO]{unicode-math}
\DeclareSymbolFont{\mathnormal}{letters}
\usepackage{lastpage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Fill in the appropriate information below
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}     
\newcommand\course{ECON - 8070}                            % <-- course name   
\newcommand\hwnumber{ 5}                                 % <-- homework number
\newcommand\Information{Tate Mason}                        % <-- personal information
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Page setup
\pagestyle{fancy}
\headheight 35pt
\rhead{Problem Set 5}
\lhead{\today}
\lfoot{}
\pagenumbering{arabic}
\cfoot{\small\thepage}
\rfoot{}
\headsep 1.2em
\renewcommand{\baselinestretch}{1.25}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Add new commands here
\renewcommand{\labelenumi}{\alph{enumi})}
\newcommand{\Z}{\mathbb Z}
\newcommand{\R}{\mathbb R}
\newcommand{\Q}{\mathbb Q}
\newcommand{\NN}{\mathbb N}
\newcommand{\PP}{\mathbb P}
\newcommand{\EE}{\mathbb E}
\newcommand{\var}{\text{var}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\Mod}{Mod} 
\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}
\newtheorem*{theorem}{Theorem}
\newtheorem*{lemma}{Lemma}
\newtheorem{case}{Case}
\newcommand{\assign}{:=}
\newcommand{\infixiff}{\text{ iff }}
\newcommand{\nobracket}{}
\newcommand{\backassign}{=:}
\newcommand{\tmmathbf}[1]{\ensuremath{\boldsymbol{#1}}}
\newcommand{\tmop}[1]{\ensuremath{\operatorname{#1}}}
\newcommand{\tmtextbf}[1]{\text{{\bfseries{#1}}}}
\newcommand{\tmtextit}[1]{\text{{\itshape{#1}}}}

\newenvironment{itemizedot}{\begin{itemize} \renewcommand{\labelitemi}{$\bullet$}\renewcommand{\labelitemii}{$\bullet$}\renewcommand{\labelitemiii}{$\bullet$}\renewcommand{\labelitemiv}{$\bullet$}}{\end{itemize}}
\catcode`\<=\active \def<{
\fontencoding{T1}\selectfont\symbol{60}\fontencoding{\encodingdefault}}
\catcode`\>=\active \def>{
\fontencoding{T1}\selectfont\symbol{62}\fontencoding{\encodingdefault}}
\catcode`\<=\active \def<{
\fontencoding{T1}\selectfont\symbol{60}\fontencoding{\encodingdefault}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Begin now!

\begin{document}
  \begin{titlepage}
    \begin{center}
      \vspace*{3cm}
            
        \vspace{1cm}
        \huge
        Homework \hwnumber
            
        \vspace{1.5cm}
        \Large
            
        \textbf{\Information}                      % <-- author
            
        \vfill
        
        An \course \ Homework Assignment
            
        \vspace{1cm}
        \Large
        
        \today
            
    \end{center}
  \end{titlepage}

  \newpage
  \section*{Question 15.3}
    \subsection*{Problem}
      Let $\textbf{z}_i$ be a vector of variables. Let $z_2$ be a continuous variable, and let $d_1$ be a dummy variable.
      \subsubsection*{(a)}
        In the model
        \begin{gather*}
          \PP(y=1|\textbf{z}_1,z_2) = \Phi (\textbf{z}_1\boldsymbol{\delta}_1 + \gamma_1z_2 + \gamma_2z_2^2),
        \end{gather*}
        find the partial effects of $z_2$ on the response probability. How would you estimate this partial effect?
      \subsubsection*{(b)}
        In the model
        \begin{gather*}
          \PP(y=1|\textbf{z}_1, z_2, d_1) = \Phi(\textbf{z}_1\boldsymbol{\delta}_1 + \gamma_1z_2 + \gamma_2d_1 + \gamma_3z_2d_1),
        \end{gather*}
        find the partial effects of $z_2$. How would you estimate the effect of $d_1$ on the response probability? How would you estimate these effects?
      \subsubsection*{(c)}
        Describe how you would obtain the standard errors of the estimated partial effects from parts a and b.
    \subsection*{Solution}
      \subsubsection*{(a)}
        To get the partial effect of $z_2$ on the response probability, we will take the partial derivative with respect to $z_2$
        \begin{gather*}
          G(z) = \Phi(z) \equiv \int\limits_{-\infty}^{(\textbf{z}_1\boldsymbol{\delta}_1 + \gamma_1z_2 + \gamma_2z_2^2)}\phi(z)dz \\
          \phi(z) = (2\pi)^{-\frac{1}{2}}\exp(-\textbf{z}_1\boldsymbol{\delta}_1 + \gamma_1z_2 + \gamma_2z_2^2)^2/2) \\
          \frac{\partial p(z)}{\partial z_2} = \phi(\textbf{z}_1\boldsymbol{\delta}_1 + \gamma_1z_2 + \gamma_2z_2^2)(\gamma_1+2\gamma_2z_2)
        \end{gather*}
        This partial effect can be estimated by Probit regression.
      \subsubsection*{(b)}
        To get the partial effect of $z_2$, we follow the same protocol as in (a)
        \begin{gather*}
          G(z) = \Phi(z) \equiv \int\limits_{-\infty}^{(\textbf{z}_1\boldsymbol{\delta}_1 + \gamma_1z_2 + \gamma_2d_1 + \gamma_3z_2d_1)}\phi(z)dz \\
          \phi(z) = (2\pi)^{-\frac{1}{2}}\exp(-\textbf{z}_1\boldsymbol{\delta}_1 + \gamma_1z_2 + \gamma_2d_1 + \gamma_3z_2d_1)^2/2) \\
          \frac{\partial p(z)}{\partial z_2} = \phi(\textbf{z}_1\boldsymbol{\delta}_1 + \gamma_1z_2 + \gamma_2z_2^2)(\gamma_1+2\gamma_3d_1)
        \end{gather*}
        To estimate the effects of $d_1$, we would then evaluate the partial effects at $d_1 = 1, 0$.
        \begin{gather*}
          d_1 = 1 \rightarrow \phi(z)(\gamma_1 + \gamma_3) \\
          d_1 = 0 \rightarrow \phi(z)(\gamma_1)
        \end{gather*}
        This would be estimated, again, by a Probit model, being sure to include the interaction term $z_2\times d_1$
      \subsubsection*{(c)}
        Using the delta method, we would be able to ascertain the standard errors for both parts.
\section*{Question 15.5}
  \subsection*{Problem}
    Consider the probit model
    \begin{gather*}
      \PP(y=1|\textbf{z},q) = \Phi(\textbf{z}_1\boldsymbol{\delta}_1+\gamma z_2q),
    \end{gather*}
    where q is independent of $\textbf{z}$ and distributed as $N(0,1)$; the vector $\textbf{z}$ is observed but the scalar $\textbf{q}$ is not.
    \subsubsection*{(a)}
      Find the partial effect of $z_2$ on the response probability, namely,
      \begin{gather*}
        \frac{\partial\PP(y=1|\textbf{z},q)}{\partial z_2}
      \end{gather*}
    \subsubsection*{(b)}
      Show that $\PP(y=1|\textbf{z}) = \Phi[\textbf{z}_1{\boldsymbol\delta}_1/(1+\gamma_1\gamma_2)^{\frac{1}{2}}]$
    \subsubsection*{(c)}
      Define $\rho_1 \equiv \gamma_1^2$. How would you test $\text{H}_0: \rho_1=0$?
    \subsubsection*{(d)}
      If you have a reason to believe $\rho_1>0$, how would you estimate $\boldsymbol{\delta}_1$ along with $\rho_1$?
  \subsection*{Solution}
    \subsubsection*{(a)}
      Following a similar protocol to the questions in 15.3,
      \begin{gather*}
        G(z) = \Phi(z) \equiv \int\limits_{-\infty}^{\textbf{z}_1\boldsymbol{\delta}+\gamma_1z_2q}\phi(z)dz \\
        \phi(z) = (2\pi)^{-\frac{1}{2}}\exp(\textbf{z}_1\boldsymbol{\delta}+\gamma_1z_2q) \\
        \frac{\partial p(z)}{\partial z_2} = \phi(\textbf{z}_1\boldsymbol{\delta}+\gamma_1z_2q)(\gamma_1q)
      \end{gather*}
    \subsubsection*{(b)}
      \begin{gather*}
        y = \mathbb{1}\{z_1\delta_1+\gamma_1z_2q+\epsilon\} \\
        e = \gamma_1z_2q+\epsilon \\
        e \sim N(0, 1+\gamma_1^2z_2^2) \\
        \PP(e\geq\textbf{z}_1\boldsymbol{\delta}_1) \\
        \PP(e\leq\textbf{z}_1\boldsymbol{\delta}_1) \\
        = \Phi(\frac{(\textbf{z}_1\boldsymbol{\delta}_1)}{(\gamma_1z_2)^{\frac{1}{2}}})
      \end{gather*}
    \subsubsection*{(c)}
      To test $H_0: \ \rho_1 = 0$, such that $\rho_1 \equiv \gamma_1^2$, we would use the Langrange multiplier test.
    \subsubsection*{(d)}
      Using maximum likelihood estimation, we could estimate $\boldsymbol{\delta}_1$ and $\rho_1$. 
\section*{Question 19.7}
  \subsection*{Problem}
    Suppose in section 19.6.1, we replace assumption 19.1d with
    \begin{gather*}
      \EE(u_1 \mid v_2)=\gamma_1 v_2+\gamma_2(v_2^2-1) .
    \end{gather*}
    (We subtract unity from $v_2^2$ to ensure that the second term has zero expectation.)
    \subsubsection*{(a)}
      Using the fact that $\operatorname{Var}(v_2 \mid v_2>-a)=1-\lambda(a)[\lambda(a)+a]$, show that
      \begin{gather*}
        \mathrm{E}(y_1 \mid \mathbf{x}, y_2=1)=\mathbf{x}_1 \boldsymbol{\beta}_1+\gamma_1 \lambda(\mathbf{x} \boldsymbol{\delta}_2)-\gamma_2 \lambda(\mathbf{x} \boldsymbol{\delta}_2) \mathbf{x} \boldsymbol{\delta}_2 .
      \end{gather*}
    [Hint: Take $a=\mathbf{x} \boldsymbol{\delta}_2$ and use the fact that $\mathrm{E}(v_2^2 \mid v_2>-a)=\operatorname{Var}(v_2 \mid v_2>-a)+$ $[\mathrm{E}(v_2 \mid v_2>-a)]^2$.]
    \subsubsection*{(b)}
      Explain how to correct for sample selection in this case.
  \subsection*{Solutions}
    \subsubsection*{(a)}
      \begin{proof}
        We are given a few definitions which will be valuable to list. Firstly, $a = \textbf{x}\boldsymbol{\delta}_2$. This is useful given $\EE(v_2^2|v_2>-a) = \var(v_2|v_2>-a) + \EE(v_2|v_2>-a)^2$ and $\var(v_2|v_2>-a) = 1-\lambda(a)[\lambda(a)+a]$. When substituting for a, $\var(v_2|v_2>-\textbf{x}\boldsymbol{\delta}_2) = 1 - \lambda(\textbf{x}\boldsymbol{\delta}_2)[\lambda(\textbf{x}\boldsymbol{\delta}_2)+\textbf{x}\boldsymbol{\delta}_2]$. So, $\EE(v_2|v_2>-\textbf{x}\boldsymbol{\delta}_2) = \lambda(\textbf{x}\boldsymbol{\delta}_2)$ and $\EE(v_2^2|v_2>-a) = 1 - \lambda(\textbf{x}\boldsymbol{\delta}_2)[\lambda(\textbf{x}\boldsymbol{\delta}_2)+\textbf{x}\boldsymbol{\delta}_2] + [\lambda(\textbf{x}\boldsymbol{\delta}_2)^2]$. Thus, we can move on, saying that $\EE(u|v_2>-\textbf{x}\boldsymbol{\delta}_2) = \gamma_1\EE(v_2|v_2>-\textbf{x}\boldsymbol{\delta}_2) + \gamma_2\EE(v_2^2|v_2>-\textbf{x}\boldsymbol{\delta}_2)$. When plugging in results, we get $\EE(u|v_2) = \gamma_1\lambda(\textbf{x}\boldsymbol{\delta}_2) + \gamma_2([1-\lambda(\textbf{x}\boldsymbol{\delta}_2)(\lambda(\textbf{x}\boldsymbol{\delta}_2)+\textbf{x}\boldsymbol{\delta}_2)+\lambda(\textbf{x}\boldsymbol{\delta}_2)^2]-1)$. After collecting terms, we are left with $\EE(u|v_2) = \gamma_1\lambda(\textbf{x}\boldsymbol{\delta}_2) - \gamma_2\lambda(\textbf{x}\boldsymbol{\delta}_2)\textbf{x}\boldsymbol{\delta}_2$. Then, we can conclude by saying that $\EE(y|x,y_2=1) = \textbf(x)_1\boldsymbol(\beta)_1 + \gamma_1\lambda(\textbf{x}\boldsymbol{\delta}_2) - \gamma_2\lambda(\textbf{x}\boldsymbol{\delta}_2)\textbf{x}\boldsymbol{\delta}_2$
      \end{proof}
    \subsubsection*{(b)}
      First, obtain the probit estimate for $y_2$. Then obtain the inverse mills ratio for each observation. Then, run OLS on the equation we derived in part a.
\end{document}
