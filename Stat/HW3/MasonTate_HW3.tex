%% Homework 3 - ECON 8070 %%
\documentclass[10pt, a4paper]{article}
\usepackage[top=3cm, bottom=4cm, left=3.5cm, right=3.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd, fancyhdr, color, comment, graphicx, environ}
\usepackage{float}
\usepackage{mathrsfs}
\usepackage[math-style=ISO]{unicode-math}
\DeclareSymbolFont{\mathnormal}{letters}
\usepackage{lastpage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Fill in the appropriate information below
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}     
\newcommand\course{ECON - 8070}                            % <-- course name   
\newcommand\hwnumber{ 3}                                 % <-- homework number
\newcommand\Information{Tate Mason}                        % <-- personal information
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Page setup
\pagestyle{fancy}
\headheight 35pt
\rhead{Problem Set 3}
\lhead{\today}
\lfoot{}
\pagenumbering{arabic}
\cfoot{\small\thepage}
\rfoot{}
\headsep 1.2em
\renewcommand{\baselinestretch}{1.25}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Add new commands here
\renewcommand{\labelenumi}{\alph{enumi})}
\newcommand{\Z}{\mathbb Z}
\newcommand{\R}{\mathbb R}
\newcommand{\Q}{\mathbb Q}
\newcommand{\NN}{\mathbb N}
\newcommand{\PP}{\mathbb P}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\Mod}{Mod} 
\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}
\newtheorem*{theorem}{Theorem}
\newtheorem*{lemma}{Lemma}
\newtheorem{case}{Case}
\newcommand{\assign}{:=}
\newcommand{\infixiff}{\text{ iff }}
\newcommand{\nobracket}{}
\newcommand{\backassign}{=:}
\newcommand{\tmmathbf}[1]{\ensuremath{\boldsymbol{#1}}}
\newcommand{\tmop}[1]{\ensuremath{\operatorname{#1}}}
\newcommand{\tmtextbf}[1]{\text{{\bfseries{#1}}}}
\newcommand{\tmtextit}[1]{\text{{\itshape{#1}}}}

\newenvironment{itemizedot}{\begin{itemize} \renewcommand{\labelitemi}{$\bullet$}\renewcommand{\labelitemii}{$\bullet$}\renewcommand{\labelitemiii}{$\bullet$}\renewcommand{\labelitemiv}{$\bullet$}}{\end{itemize}}
\catcode`\<=\active \def<{
\fontencoding{T1}\selectfont\symbol{60}\fontencoding{\encodingdefault}}
\catcode`\>=\active \def>{
\fontencoding{T1}\selectfont\symbol{62}\fontencoding{\encodingdefault}}
\catcode`\<=\active \def<{
\fontencoding{T1}\selectfont\symbol{60}\fontencoding{\encodingdefault}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Begin now!

\begin{document}
  \begin{titlepage}
    \begin{center}
      \vspace*{3cm}
            
        \vspace{1cm}
        \huge
        Homework \hwnumber
            
        \vspace{1.5cm}
        \Large
            
        \textbf{\Information}                      % <-- author
            
        \vfill
        
        An \course \ Homework Assignment
            
        \vspace{1cm}
        \Large
        
        \today
            
    \end{center}
  \end{titlepage}

  \newpage
  \section*{10.1}
    \subsection*{Problem}
      Let $X$ be distributed Poisson: $\pi(k)=\frac{\exp(-\theta)\theta^k}{k!}$ for nonnegative integer $k$ and $\theta>0$.

      (a) Find the log-likelihood function $l_n(\theta)$.

      (b) Find the MLE $\hat \theta$ for $\theta$ 
    \subsection*{Solution}
      (a) We can obtain log likelihood by first finding the likelihood function 
      \begin{center}
        $L(\theta)=\Pi^n_{i=1}[\frac{(\exp(-\theta)*\theta^{k_i})}{k_i!}]$
      \end{center}
      Then, we take the natural log
      \begin{center}
        $l_n(\theta)=\log(L(\theta))=\sum_{i=1}^n[\log(\exp(-\theta))+k_1\log(\theta)-\log(k_i!)]$ \\
        $ = \sum_{i=1}^n[-\theta+k_i\log(\theta)-\log(k_i!)]$ \\
        $\boxed{= -n\theta +\log(\theta)\sum_{i=1}^nk_i-\sum_{i=1}^n\log(k_i!)}$  
      \end{center}

      (b) Now we need to find $\hat \theta={\argmax\atop{\theta\in\Theta}}l_n(\theta)$. We can do this by taking the derivative of $l_n$ w.r.t $\theta$ 
      \begin{center}
        $\frac{dl_n(\theta)}{d\theta} = -n + \frac{1}{\theta}\sum_{i=1}^n k_i=0$ \\
      \end{center}

      Then, we solve for $\hat\theta$
      \begin{center}
        $\theta n = \sum_{i=1}^n k_i$ \\
        $\boxed{\hat\theta = \frac{1}{n}\sum_{i=1}^n k_i}$
      \end{center}

      The MLE is the sample mean.
    

  \section*{10.6}
    \subsection*{Problem}
      Let $X$ be Bernoulli $\pi(X|p)=p^x(1-p)^{1-x}$.

      (a) Calculate the information for $p$ by taking the variance of the score.

      (b) Calculate the information for $p$ by taking the expectation of (minus) the second derivative. Did you obtain the same answer? 
    \subsection*{Solution}
      (a) Let's start with log-likelihood:
      \begin{center}
        $l(p) = x\log(p)+(1-x)\log(p)$
      \end{center}
      To find the score, we differentiate w.r.t. $p$
      \begin{center}
        $S(p)=\frac{x}{p}-\frac{(1-x)}{(1-p)}$
      \end{center}
      Next, we will find the variance such that $\var[S(p)]=\mathbb{E}(S(p)^2)$
      \begin{center}
        $\mathbb{E}(s(p)^2)=\mathbb{E}(\frac{x^2}{p^2})+\mathbb{E}(\frac{(1-x)^2}{(1-p)^2}) = \frac{1}{p}+\frac{1}{(1-p)}$\\
        $\boxed{\therefore \mathcal{I} = \frac{1}{p(1-p)}}$
      \end{center}
      (b) Second derivative 
      \begin{center}
        $\frac{d^2l(p)}{dp^2}=\frac{-x}{p^2}-\frac{(1-x)}{(1-p)^2}$ \\
      \end{center}
      Negative expectation
      \begin{center}
        $\mathcal{I}(p)=-\mathbb{E}(\frac{d^2l(p)}{dp^2}=\frac{-x}{p^2}-\frac{(1-x)}{(1-p)^2})$\\
        $ = \mathbb{E}(\frac{x}{p^2})+\mathbb{E}(\frac{1-x}{(1-p)^2})$ \\
        $ = \frac{p}{p^2}+\frac{(1-p)}{(1-p)^2}$ \\
        $ = \frac{1}{p}+\frac{1}{(1-p)}$ \\
        $\boxed{ = \frac{1}{p(1-p)}}$ 
      \end{center}
  \section*{11.3}
    \subsection*{Problem}
      A Bernoulli random variable $X$ is
      \begin{center}
        $\PP[X=0]=1-p$ \\
        $\PP[X=1]=p$ \\
      \end{center}

      (a) Propose a moment estimator $\hat p$ for $p$.

      (b) Find the variance of the asymptotic distribution of $\sqrt{n}(\hat p-p)$

    \subsection*{Solution}
      (a) The first moment of a Bernoulli is the mean
      \begin{center}
        $\mathbb{E}[X]=p$
      \end{center}
      The method of moments for p, here, is the sample mean
      \begin{center}
        $\boxed{hat p = \frac{1}{n}\sum_{i=1}^nX_i}$
      \end{center}
      (b) For a Bernoulli distribution $\var(X)=p(1-p)$. We can use central limit theorem to deduce $\sqrt{n(\hat p-p)}\rightarrow N(0,\sigma^2)$. We can put these together since $\sigma^2 = \var(X)$. So, the asymptotic distribution is $\sqrt{n(p\hat p-p)} \rightarrow N(0,p(1-p))$ 
  \section*{11.4}
    \subsection*{Problem}
      Propse a moment estimator $\hat\lambda$ for the parameter $\lambda$ of a Poisson distribution.  
    \subsection*{Solution}
      A Poisson distribution has distribution $\EE[X]=\lambda$. As seen in the Bernoulli case, the moment estimator for $\lambda$ is the sample mean
      \begin{center}
        $\boxed{\hat\lambda = \frac{1}{n}\sum_{i=1}^n X_i}$
      \end{center}
  \section*{13.3}
    \subsection*{Problem}
      Take the exponential model with parameter $\lambda$. We want a test for $\mathbb{H}_0:\lambda=1$ against $\mathbb{H}_1:\lambda\ne1$.

      (a) Develop a test based on the sample mean $\bar X_n$.
    \subsection*{Solution}

  \section*{13.5}
    \subsection*{Problem}
      Take the model $X\dist N(\mu,\sigma^2)$. Propose a test for $\mathbb{H}_0:\mu=1$ against $\mathbb{H}_1:\mu\ne1$. 
    \subsection*{Solution}
\end{document}
